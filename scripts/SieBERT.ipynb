{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SieBERT sentiment analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install pandas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model, tokenizer, and trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"siebert/sentiment-roberta-large-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "trainer = Trainer(model=model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create class for data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDataset:\n",
    "    '''This class creates an object containing tokenized_texts, and provides two methods to interact with the data: \n",
    "    The __len__ method returns the length of the \"input_ids\" in the tokenized_texts dictionary. \n",
    "    The __getitem__ method returns a dictionary containing the key-value pairs in the tokenized_texts dictionary, with the value corresponding to the index provided as the argument for the method. '''\n",
    "    def __init__(self, tokenized_texts):\n",
    "        self.tokenized_texts = tokenized_texts\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_texts[\"input_ids\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data and transform into lists, tokenize texts, and create prediction datasets**\n",
    "\n",
    "NB: Define the correct path to the topic_reviews_df, generated in the BERTopic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'/PATH/topic_reviews_df.csv')\n",
    "\n",
    "def Topic2Obj(data, topic_nr):\n",
    "    '''\n",
    "    This function takes a dataframe and a specified topic. \n",
    "    Creates a list of reviews and a SimpleDataset object for a specified topic number.\n",
    "    Tokenizes texts.\n",
    "    Returns a list and SimpleDataset object.'''\n",
    "    top = data.loc[data['topic'] == topic_nr]\n",
    "    top_list = top['review'].to_list()\n",
    "    tok = tokenizer(top_list, truncation = True, padding = True)\n",
    "    obj = SimpleDataset(tok)\n",
    "    return(top_list, obj)\n",
    "\n",
    "t_0_list, t_0_ob = Topic2Obj(data, 0)\n",
    "t_1_list, t_1_ob = Topic2Obj(data, 1)\n",
    "t_2_list, t_2_ob = Topic2Obj(data, 2)\n",
    "t_3_list, t_3_ob = Topic2Obj(data, 3)\n",
    "t_4_list, t_4_ob = Topic2Obj(data, 4)\n",
    "t_5_list, t_5_ob = Topic2Obj(data, 5)\n",
    "t_6_list, t_6_ob = Topic2Obj(data, 6)\n",
    "t_8_list, t_8_ob = Topic2Obj(data, 8)\n",
    "t_9_list, t_9_ob = Topic2Obj(data, 9)\n",
    "t_10_list, t_10_ob = Topic2Obj(data, 10)\n",
    "t_12_list, t_12_ob = Topic2Obj(data, 12)\n",
    "t_14_list, t_14_ob = Topic2Obj(data, 14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunPred(ob, data_list, topic):\n",
    "    '''\n",
    "    This function takes a SimpleDataset object, list of reviews, and specified topic.\n",
    "    Predicts sentiment scores for the object.\n",
    "    Assigns a label of most probable sentiment (positive/negative). \n",
    "    Creates a dataframe with text and corresponding labels, scores, and topic numnber.\n",
    "    Returns dataframe.\n",
    "    '''\n",
    "    out = trainer.predict(ob)\n",
    "    preds = out.predictions.argmax(-1)\n",
    "    labels = pd.Series(preds).map(model.config.id2label)\n",
    "    scores = (np.exp(out[0])/np.exp(out[0]).sum(-1,keepdims=True)).max(1)\n",
    "    df_pred = pd.DataFrame(list(zip(data_list,preds,labels,scores)), columns=['text','pred','label','score'])\n",
    "    df_pred[\"topic\"] = topic\n",
    "    return df_pred\n",
    "\n",
    "t_0_preds = RunPred(t_0_ob, t_0_list, \"topic_0\")\n",
    "t_1_preds = RunPred(t_1_ob, t_1_list, \"topic_1\")\n",
    "t_2_preds = RunPred(t_2_ob, t_2_list, \"topic_2\")\n",
    "t_3_preds = RunPred(t_3_ob, t_3_list, \"topic_3\")\n",
    "t_4_preds = RunPred(t_4_ob, t_4_list, \"topic_4\")\n",
    "t_5_preds = RunPred(t_5_ob, t_5_list, \"topic_5\")\n",
    "t_6_preds = RunPred(t_6_ob, t_6_list, \"topic_6\")\n",
    "t_8_preds = RunPred(t_8_ob, t_8_list, \"topic_8\")\n",
    "t_9_preds = RunPred(t_9_ob, t_9_list, \"topic_9\")\n",
    "t_10_preds = RunPred(t_10_ob, t_10_list, \"topic_10\")\n",
    "t_12_preds = RunPred(t_12_ob, t_12_list, \"topic_12\")\n",
    "t_14_preds = RunPred(t_14_ob, t_14_list, \"topic_14\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract percentages of positive and negative sentiment relative to each topic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_count_percentages(dataframe, column):\n",
    "    '''\n",
    "    This function takes a dataframe containing topic number and sentiment labels.\n",
    "    Calculates percentages of how many reviews are predicted as positive or negative according to the number of documents in the topic.\n",
    "    Returns a dataframe of percentages.\n",
    "    '''\n",
    "    # Create an empty list to store the counts and percentages\n",
    "    counts_percentages = []\n",
    "    \n",
    "    # Get the total occurrences in the column\n",
    "    total_occurrences = dataframe[column].count()\n",
    "    \n",
    "    # Get the unique values in the column\n",
    "    unique_values = dataframe[column].unique()\n",
    "    \n",
    "    # Iterate through each unique value\n",
    "    for value in unique_values:\n",
    "        # Get the number of occurrences for the current value\n",
    "        current_value_occurrences = dataframe[dataframe[column] == value].count()[0]\n",
    "        # Calculate the percentage of occurrences for the current value\n",
    "        percentage = current_value_occurrences / total_occurrences * 100\n",
    "        # Append the percentage to the list\n",
    "        counts_percentages.append([value, percentage])\n",
    "        #counts_percentages = pd.DataFrame(counts_percentages)\n",
    "    \n",
    "    counts_percentages = pd.DataFrame(counts_percentages)\n",
    "    topic = dataframe[\"topic\"].unique()\n",
    "    counts_percentages[\"topic\"] = (topic, topic)\n",
    "    \n",
    "    # Return the list of counts and percentages\n",
    "    return counts_percentages\n",
    "\n",
    "# get_string_count_percentages(t_4_preds, 'label')\n",
    "\n",
    "#List of dfs to loop through\n",
    "df_list = [t_0_preds, t_1_preds, t_2_preds, t_3_preds, t_4_preds, t_5_preds, t_6_preds, t_8_preds, t_9_preds, t_10_preds, t_12_preds, t_14_preds]\n",
    "\n",
    "# Create an empty dataframe to store the results\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "# Loop over the dataframes in the list\n",
    "for df in df_list:\n",
    "\n",
    "    # Pass each dataframe through your function\n",
    "    new_df = get_string_count_percentages(df, 'label')\n",
    "    \n",
    "    # Concatenate the resulting dataframe to the result_df\n",
    "    result_df = pd.concat([result_df, new_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Print the result dataframe\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (v3.9.10:f2f3f53782, Jan 13 2022, 16:55:45) \n[Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
